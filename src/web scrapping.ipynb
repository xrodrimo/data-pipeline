{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup #Â pip install beautifulsoup4\n",
    "import pandas as pd\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On my url i have the information  organizen in 3 levels\n",
    "# Main Structure (\"div\", {\"class\":\"m-1wi74ow\"})\n",
    "    # 5 Sub Groups (TOP,MIDDLE,ADC,SUPPORT,JUNGLE) (\"div\", {\"class\":\"m-1twnwk2\"})\n",
    "        # 3 Tier's (S,A,B) (\"div\", {\"class\":\"m-kvvnsa\"})\n",
    "            # Inside we have the names of the chamions (\"span\", {\"class\":\"m-1hxcjhy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. SUPPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_sup = \"https://mobalytics.gg/lol/tier-list?iRole=SUPPORT\" # We slect our URL\n",
    "html_sup = requests.get(url_sup).content # With the library \"request\" we ask to get al content on the previous URL selected\n",
    "soup_sup = BeautifulSoup(html_sup,'html.parser') # Parsing HTML involves breaking down the HTML code into its individual components, such as elements, attributes, and their values.\n",
    "tier_divs_sup = soup_sup.find_all(\"div\", {\"class\": \"m-kvvnsa\"})  # Find all div elements with class \"m-kvvnsa\"\n",
    "suport_list_sup = [[span.getText() for span in div.find_all(\"span\", {\"class\": \"m-1hxcjhy\"})]for div in tier_divs_sup] # For each div element, find span elements with class \"m-1hxcjhy\" and collect their text content\n",
    "tier_s_sup = suport_list_sup[0] \n",
    "tier_a_sup = suport_list_sup[1]\n",
    "tier_b_sup = suport_list_sup[2]\n",
    "# now i create the dataframes with the list obtained from the DATAWRAPING\n",
    "sup_s = pd.DataFrame(tier_s_sup, columns=['Champion'])\n",
    "sup_s['Tier'] = 'S'\n",
    "sup_a = pd.DataFrame(tier_a_sup, columns=['Champion'])\n",
    "sup_a['Tier'] = 'A'\n",
    "sup_b = pd.DataFrame(tier_b_sup, columns=['Champion'])\n",
    "sup_b['Tier'] = 'B'\n",
    "\n",
    "result_sup = pd.concat([sup_s, sup_a, sup_b], ignore_index=True)\n",
    "result_sup['Class'] = 'Support'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. JUNGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_jung = \"https://mobalytics.gg/lol/tier-list?iRole=JUNGLE\" # We slect our URL\n",
    "html_jung = requests.get(url_jung).content # With the library \"request\" we ask to get al content on the previous URL selected\n",
    "soup_jung = BeautifulSoup(html_jung,'html.parser') # Parsing HTML involves breaking down the HTML code into its individual components, such as elements, attributes, and their values.\n",
    "tier_divs_jung = soup_jung.find_all(\"div\", {\"class\": \"m-kvvnsa\"})  # Find all div elements with class \"m-kvvnsa\"\n",
    "suport_list_jung = [[span.getText() for span in div.find_all(\"span\", {\"class\": \"m-1hxcjhy\"})]for div in tier_divs_jung] # For each div element, find span elements with class \"m-1hxcjhy\" and collect their text content\n",
    "tier_s_jung = suport_list_jung[0] \n",
    "tier_a_jung = suport_list_jung[1]\n",
    "tier_b_jung = suport_list_jung[2]\n",
    "# now i create the dataframes with the list obtained from the DATAWRAPING\n",
    "jung_s = pd.DataFrame(tier_s_jung, columns=['Champion'])\n",
    "jung_s['Tier'] = 'S'\n",
    "jung_a = pd.DataFrame(tier_a_jung, columns=['Champion'])\n",
    "jung_a['Tier'] = 'A'\n",
    "jung_b = pd.DataFrame(tier_b_jung, columns=['Champion'])\n",
    "jung_b['Tier'] = 'B'\n",
    "\n",
    "result_jung = pd.concat([jung_s, jung_a, jung_b], ignore_index=True)\n",
    "result_jung['Class'] = 'Jungle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Adc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_adc = \"https://mobalytics.gg/lol/tier-list?iRole=ADC\" # We slect our URL\n",
    "html_adc = requests.get(url_adc).content # With the library \"request\" we ask to get al content on the previous URL selected\n",
    "soup_adc = BeautifulSoup(html_adc,'html.parser') # Parsing HTML involves breaking down the HTML code into its individual components, such as elements, attributes, and their values.\n",
    "tier_divs_adc = soup_adc.find_all(\"div\", {\"class\": \"m-kvvnsa\"})  # Find all div elements with class \"m-kvvnsa\"\n",
    "adc_list = [[span.getText() for span in div.find_all(\"span\", {\"class\": \"m-1hxcjhy\"})]for div in tier_divs_adc] # For each div element, find span elements with class \"m-1hxcjhy\" and collect their text content\n",
    "tier_s_adc= adc_list[0] \n",
    "tier_a_adc = adc_list[1]\n",
    "tier_b_adc = adc_list[2]\n",
    "# now i create the dataframes with the list obtained from the DATAWRAPING\n",
    "adc_s = pd.DataFrame(tier_s_adc, columns=['Champion'])\n",
    "adc_s['Tier'] = 'S'\n",
    "adc_a = pd.DataFrame(tier_a_adc, columns=['Champion'])\n",
    "adc_a['Tier'] = 'A'\n",
    "adc_b = pd.DataFrame(tier_b_adc, columns=['Champion'])\n",
    "adc_b['Tier'] = 'B'\n",
    "\n",
    "result_adc = pd.concat([adc_s, adc_a, adc_b], ignore_index=True)\n",
    "result_adc['Class'] = 'Adc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_TOP = \"https://mobalytics.gg/lol/tier-list?iRole=TOP\" # We slect our URL\n",
    "html_TOP = requests.get(url_TOP).content # With the library \"request\" we ask to get al content on the previous URL selected\n",
    "soup_TOP = BeautifulSoup(html_TOP,'html.parser') # Parsing HTML involves breaking down the HTML code into its individual components, such as elements, attributes, and their values.\n",
    "tier_divs_TOP = soup_jung.find_all(\"div\", {\"class\": \"m-kvvnsa\"})  # Find all div elements with class \"m-kvvnsa\"\n",
    "top_list = [[span.getText() for span in div.find_all(\"span\", {\"class\": \"m-1hxcjhy\"})]for div in tier_divs_TOP] # For each div element, find span elements with class \"m-1hxcjhy\" and collect their text content\n",
    "tier_s_TOP = top_list[0] \n",
    "tier_a_TOP = top_list[1]\n",
    "tier_b_TOP = top_list[2]\n",
    "# now i create the dataframes with the list obtained from the DATAWRAPING\n",
    "TOP_s = pd.DataFrame(tier_s_TOP, columns=['Champion'])\n",
    "TOP_s['Tier'] = 'S'\n",
    "TOP_a = pd.DataFrame(tier_a_TOP, columns=['Champion'])\n",
    "TOP_a['Tier'] = 'A'\n",
    "TOP_b = pd.DataFrame(tier_b_TOP, columns=['Champion'])\n",
    "TOP_b['Tier'] = 'B'\n",
    "\n",
    "result_top = pd.concat([TOP_s, TOP_a, TOP_b], ignore_index=True)\n",
    "result_top['Class'] = 'Top'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. MIDDLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_mid= \"https://mobalytics.gg/lol/tier-list?iRole=MID\" # We slect our URL\n",
    "html_mid = requests.get(url_mid).content # With the library \"request\" we ask to get al content on the previous URL selected\n",
    "soup_mid = BeautifulSoup(html_mid,'html.parser') # Parsing HTML involves breaking down the HTML code into its individual components, such as elements, attributes, and their values.\n",
    "tier_divs_mid = soup_mid.find_all(\"div\", {\"class\": \"m-kvvnsa\"})  # Find all div elements with class \"m-kvvnsa\"\n",
    "mid_list = [[span.getText() for span in div.find_all(\"span\", {\"class\": \"m-1hxcjhy\"})]for div in tier_divs_mid] # For each div element, find span elements with class \"m-1hxcjhy\" and collect their text content\n",
    "tier_s_mid = mid_list[0] \n",
    "tier_a_mid = mid_list[1]\n",
    "tier_b_mid = mid_list[2]\n",
    "# now i create the dataframes with the list obtained from the DATAWRAPING\n",
    "mid_s = pd.DataFrame(tier_s_mid, columns=['Champion'])\n",
    "mid_s['Tier'] = 'S'\n",
    "mid_a = pd.DataFrame(tier_a_mid, columns=['Champion'])\n",
    "mid_a['Tier'] = 'A'\n",
    "mid_b = pd.DataFrame(tier_b_jung, columns=['Champion'])\n",
    "mid_b['Tier'] = 'B'\n",
    "result_mid = pd.concat([mid_s, mid_a, mid_b], ignore_index=True)\n",
    "result_mid['Class'] = 'Middle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Now we compact all lists and export the resuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Champion Tier   Class\n",
      "0           Naafiri    S  Middle\n",
      "1             Sylas    S  Middle\n",
      "2           Taliyah    S  Middle\n",
      "3          Vladimir    S  Middle\n",
      "4            Syndra    S  Middle\n",
      "..              ...  ...     ...\n",
      "165          Rammus    B     Top\n",
      "166          Rengar    B     Top\n",
      "167              Vi    B     Top\n",
      "168         Kindred    B     Top\n",
      "169  Nunu & Willump    B     Top\n",
      "\n",
      "[170 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "results = pd.concat([result_mid, result_sup, result_adc, result_jung,result_top], ignore_index=True)\n",
    "print(results)\n",
    "# Save the DataFrame to a CSV file\n",
    "results.to_csv('../data/Champions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
